"""
predict.py
-------------------------------------
Loads the trained credit risk model from MLflow Production stage
and performs predictions. Works for batch inference or CLI usage.
"""
import os
import yaml
import mlflow
import mlflow.sklearn
from mlflow.tracking import MlflowClient
from fastapi import HTTPException
import pandas as pd
import pathlib

# ============================================================
# 1Ô∏è‚É£ Load configuration
# ============================================================
def load_config(path: str = "src/config.yaml") -> dict:
    if not os.path.exists(path):
        raise FileNotFoundError(f"‚ùå Config file not found at: {path}")
    with open(path, "r") as f:
        return yaml.safe_load(f)


# ============================================================
# 2Ô∏è‚É£ Load Production model dynamically (cross-platform safe)
# ============================================================


def load_production_model(model_name="Credit_Risk_Model"):
    """
    Loads the latest 'Production' stage model from MLflow registry.
    Works locally (Windows-safe) and in CI/CD environments.
    """
    try:
        # Detect environment
        MLFLOW_TRACKING_URI = os.getenv("MLFLOW_TRACKING_URI")

        if not MLFLOW_TRACKING_URI:
            if os.path.exists("mlruns"):
                # ‚úÖ Local file-based tracking (no registry)
                MLFLOW_TRACKING_URI = pathlib.Path("mlruns").resolve().as_uri()
            else:
                # ‚úÖ Default to local MLflow server
                MLFLOW_TRACKING_URI = "http://127.0.0.1:5000"

        mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)
        print(f"‚úÖ MLflow tracking URI: {MLFLOW_TRACKING_URI}")

        # If registry (http:// or https://) is available ‚Üí use Production stage
        if MLFLOW_TRACKING_URI.startswith("http"):
            client = MlflowClient()
            versions = client.search_model_versions(f"name='{model_name}'")
            prod_versions = [v for v in versions if v.current_stage == "Production"]

            if not prod_versions:
                raise HTTPException(status_code=503, detail=f"No Production model found for '{model_name}'")

            model_uri = f"models:/{model_name}/Production"
            model = mlflow.sklearn.load_model(model_uri)
            print(f"‚úÖ Loaded Production model {model_name} version {prod_versions[0].version}")

        else:
            # ‚úÖ File-based fallback (CI/CD or offline mode)
            latest_run = max(
                pathlib.Path("mlruns").rglob("model.pkl"),
                key=os.path.getmtime,
                default=None
            )
            if not latest_run:
                raise HTTPException(status_code=503, detail="No local model found in mlruns/")
            model = mlflow.sklearn.load_model(str(latest_run.parent))
            print(f"‚úÖ Loaded local model from: {latest_run.parent}")

        return model

    except Exception as e:
        print(f"‚ùå Failed to load model: {e}")
        raise HTTPException(status_code=503, detail="Model not loaded. Try again later.")


# ============================================================
# 3Ô∏è‚É£ Predict function
# ============================================================
def predict(model, input_data: pd.DataFrame) -> pd.DataFrame:
    expected_cols = [
        'Loan Amount',
        'Debt-to-Income Ratio',
        'Credit Score',
        'Assets Value',
        'Age',
        'Income',
        'Number of Dependents',
        'Education Level',
        'Payment History',
        'Marital Status',
        'Gender',
        'Employment Status',
        'Loan Purpose'
    ]

    missing_cols = set(expected_cols) - set(input_data.columns)
    if missing_cols:
        raise ValueError(f"Missing required columns: {missing_cols}")

    predictions = model.predict(input_data)
    probabilities = model.predict_proba(input_data)[:, 1]

    results = input_data.copy()
    results["Predicted_Risk"] = predictions
    results["Probability_HighRisk"] = probabilities.round(4)
    return results

# ============================================================
# 4Ô∏è‚É£ Example CLI usage
# ============================================================
if __name__ == "__main__":
    # Load Production model
    model = load_production_model()

    # Example input
    example_data = pd.DataFrame([{
        "Loan Amount": 50000,
        "Debt-to-Income Ratio": 0.35,
        "Credit Score": 720,
        "Assets Value": 100000,
        "Age": 35,
        "Income": 80000,
        "Number of Dependents": 2,
        "Education Level": "Bachelor's",
        "Payment History": "Good",
        "Marital Status": "Married",
        "Gender": "Male",
        "Employment Status": "Employed",
        "Loan Purpose": "Home Improvement"
    }])

    output = predict(model, example_data)
    print("\nüìä Prediction Result:")
    print(output)
